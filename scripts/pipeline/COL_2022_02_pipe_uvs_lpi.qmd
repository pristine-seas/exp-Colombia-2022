---
title: "Benthos LPI - Data Pipeline"
date: today
format: 
  html:
    theme: minty
    self-contained: true
    code-fold: true
    toc: true 
    toc-depth: 3
    toc-location: right
    html-table-processing: none
execute:
  fig-width: 10
---

```{r setup, message = F, warning = F, fig.width = 10, fig.height = 10, echo = F}
options(scipen = 999)

# Hook to format inline numeric expressions with comma separators:
knitr::knit_hooks$set(inline = function(x) {
  # For non-numeric values, just return as character
  if (!is.numeric(x)) {return(as.character(x))}
  # Format numbers with comma as big.mark, no scientific notation
  else format(x, big.mark = ",", scientific = FALSE)})

library(sf)
library(hms)
library(readxl)
library(janitor)
library(lubridate)
library(gt)
library(pointblank)
library(tidyverse)
library(bigrquery)
library(leaflet)
library(leaflet.extras)
library(ggtext)
library(PristineSeasR2)

ps_paths <- PristineSeasR2::get_drive_paths()

exp_id <- "COL_2022"

exp_path <- file.path(ps_paths$expeditions, str_replace(exp_id, "_", "-"))

bigrquery::bq_auth(email = "marine.data.science@ngs.org")

bq_connection <- DBI::dbConnect(bigrquery::bigquery(), project = "pristine-seas")
```

This documentation outlines the end-to-end pipeline for processing benthos Line Point Intercept (LPI) survey data collected during Pristine Seas expeditions. The pipeline ingests raw field data, standardizes formats, performs taxonomy lookups, applies rigorous quality assurance/quality control (QA/QC), computes station-level summaries, and loads the clean data into the Pristine Seas Science Database in BigQuery.

## Data ingestion

### Sites

We begin by reading the UVS (Underwater Visual Survey) site information and standardizing it to match our database schema. Key steps include:

  - Harmonizing field names using
  - Converting data types (e.g., date, time, boolean fields) to their appropriate formats.
  - Constructing ps_site_id using expedition and site identifiers.
  
```{r}
uvs_sites <- tbl(bq_connection, "uvs.sites") |> 
   filter(exp_id == "COL_2022") |> 
   collect()

# Validate site data
cat("Sites loaded:", nrow(uvs_sites), "\n")
cat("Regions:", unique(uvs_sites$region), "\n")
cat("Subregions:", unique(uvs_sites$subregion), "\n")
```

### Fieldbooks

Next, process field observations from different divers, ensuring consistent formatting and traceability.

  - Field names are harmonized, and units are standardized.
  - Unique observation IDs (obs_id) are generated for QA/QC.
  - Field data is cleaned and formatted to ensure database compatibility.

```{r}
sections_pacific <- read_xlsx(file.path(exp_path, "data/primary/raw/inverts/COL_contacts_fieldsheet.xlsx"),
                          sheet         = "data",
                          range         = "B1:EL3",
                          col_names     = FALSE,
                          .name_repair  = "minimal") |>
  t() |>
  as_tibble(.name_repair = "minimal") |> 
  row_to_names(row_number = 1) |>
  clean_names() |> 
  mutate(transect_section = recode(subtransect,
                                   "A" = "0-10",
                                   "B" = "10-20",
                                   "C" = "20-30",
                                   "D" = "30-40",
                                   "E" = "40-50"),
         depth_m          = parse_number(depth_m),
         divers            = paste("Kike Ballesteros | Paula Zapata"),
         site             = str_pad(parse_number(station_number), 3, pad = "0"),
         ps_site_id       = paste(exp_id, "uvs", site, sep = "_")) |> 
  select(divers, ps_site_id, depth_m, transect_section)

sections_caribe <- read_xlsx(file.path(exp_path, "data/primary/raw/inverts/SEA_contacts_fieldsheet_definitivo.xlsx"),
                          sheet         = "Point intercept",
                          range         = "B1:IW3",
                          col_names     = FALSE,
                          .name_repair  = "minimal") |>
  t() |>
  as_tibble(.name_repair = "minimal") |> 
  row_to_names(row_number = 1) |>
  clean_names() |> 
  mutate(transect_section = recode(subtransect,
                                   "A" = "0-10",
                                   "B" = "10-20",
                                   "C" = "20-30",
                                   "D" = "30-40",
                                   "E" = "40-50"),
         depth_m          = parse_number(depth_m),
         divers            = paste("Kike Ballesteros | Alfredo Abril-Howard"),
         site             = as.numeric(parse_number(station_number)) + 20,
         ps_site_id       = paste(exp_id, "uvs", str_pad(site ,3, pad = "0"), sep = "_")) |> 
  select(divers, ps_site_id, depth_m, transect_section)

sections <- bind_rows(sections_pacific, sections_caribe)

sections <- sections |> 
  left_join(sections |> 
              distinct(ps_site_id, depth_m) |> 
              group_by(ps_site_id) |> 
              mutate(transect_label = LETTERS[row_number()])) |> 
  select(ps_site_id, divers, transect_label, depth_m, transect_section) |> 
  group_by(ps_site_id, transect_label) |>
  mutate(station_depth_m = mean(depth_m, na.rm = TRUE),
         n_sections = n()) |> 
  ungroup() |> 
  mutate(exp_id         = exp_id,
         survey_type    = "uvs",
         method         = "lpi",
         depth_strata   = if_else(depth_m > 30, "superdeep", stratify(station_depth_m)),
         ps_station_id  = if_else(depth_m < 30,
                                  paste(ps_site_id, station_suffix(depth_strata), sep = "_"),
                                  paste(ps_site_id, "30m", sep = "_")),
         section_id     = paste(ps_station_id, transect_label, transect_section, sep = "_")) |> 
  select(exp_id, survey_type, ps_site_id, ps_station_id, method, divers, 
         depth_m, station_depth_m, depth_strata, transect_label, 
         transect_section, section_id)

tmp <- sections |> 
  left_join(uvs_sites |> select(ps_site_id, region)) 

section_ids_pacific <- tmp$section_id[tmp$region == "Golfo de TribugÃ¡"]
section_ids_caribe <- tmp$section_id[tmp$region != "Golfo de TribugÃ¡"]
```

```{r}
contacts_pacific <- read_xlsx(file.path(exp_path, "data/primary/raw/inverts/COL_contacts_fieldsheet.xlsx"),
                              sheet         = "data",
                              range         = "A5:EL55",
                              col_names     = FALSE,
                              .name_repair  = "minimal") |> 
  set_names(c("morphotaxon","field_name", section_ids_pacific)) |> 
  mutate(across(all_of(section_ids_pacific), as.character)) |> 
  pivot_longer(cols      = -c(field_name, morphotaxon),
               names_to  = "section_id",
               values_to = "contacts") |>
  mutate(contacts = parse_number(contacts)) |>
  filter(!is.na(contacts)) |>
  select(section_id, morphotaxon, field_name, contacts)

contacts_caribe <- read_xlsx(file.path(exp_path, "data/primary/raw/inverts/SEA_contacts_fieldsheet_definitivo.xlsx"),
                             sheet         = "Point intercept",
                             range         = "A5:IW148",
                             col_names     = FALSE,
                             .name_repair  = "minimal") |> 
  set_names(c("morphotaxon","field_name", section_ids_caribe)) |> 
  mutate(across(all_of(section_ids_caribe), as.character)) |> 
  pivot_longer(cols      = -c(field_name, morphotaxon),
                 names_to  = "section_id",
                 values_to = "contacts") |>
    mutate(contacts = parse_number(contacts)) |>
    filter(!is.na(contacts)) |>
    select(section_id, morphotaxon, field_name, contacts)

contacts <- bind_rows(contacts_pacific, contacts_caribe)

section_totals <- contacts |>
    group_by(section_id) |>
    summarise(n_points = sum(contacts, na.rm = TRUE),
              .groups  = "drop")
  
lpi_sections <- sections |>
  left_join(section_totals, by = "section_id")

lpi_contacts <- contacts |>
  left_join(select(sections, section_id, exp_id, ps_station_id, transect_label, transect_section, divers, depth_m), 
            by = "section_id") |>
  group_by(ps_station_id, exp_id, diver = divers, transect_label, depth_m, transect_section, morphotaxon, section_id) |>
  summarize(contacts = sum(contacts, na.rm = T)) |> 
  ungroup() |> 
  arrange(ps_station_id, transect_label, transect_section) 
```

## QA/QC Process

### Sections

```{r}
lpi_sections |> 
  create_agent(label = "Benthos LPI Transect sections QA/QC", tbl_name = "lpi_sections") |> 
  rows_distinct(section_id,
                label = "Section IDs are unique",
                actions = action_levels(stop_at = 0.00001)) |> 
  col_vals_between(n_points, 49, 51,
                   label = "50  points per section",) |> 
  interrogate()
```

### Stations

Validate station data to ensure consistency and completeness.

  - Ensure station IDs are unique
  - Confirm the correct number of points (typically 250 per station).
  - Enforce allowed values for habitat and exposure fields.
  
```{r}
# Summarize across sections into transect 

lpi_stations <- lpi_sections |> 
  group_by(ps_station_id, ps_site_id, exp_id, divers, depth_strata) |> 
  summarize(depth_m = round(mean(depth_m)),
            n_transects = n_distinct(transect_label),
            n_sections = n_distinct(section_id),
            n_points = sum(n_points),
            survey_dist_m = n_sections*10,
            .groups = "drop") |> 
  left_join(uvs_sites |> 
              distinct(ps_site_id, region, subregion, locality, habitat, exposure),
            by = "ps_site_id") |> 
  select(ps_station_id, ps_site_id, exp_id, region, subregion, locality, habitat, exposure, divers, depth_m, depth_strata, n_transects, survey_dist_m, n_points)
```

```{r}
# Station QA/QC using pointblank
station_qaqc <- lpi_stations |> 
  create_agent(label = "Benthos LPI Stations QA/QC", tbl_name = "lpi_stations") |> 
  rows_distinct(ps_station_id,
                label = "Station IDs are unique",
                actions = action_levels(stop_at = 0.001)) |>
  col_vals_equal(columns = vars(n_transects), 
                 value = 1,
                 label = "Expected 1 transects per station",
                 actions = action_levels(warn_at = 0.001)) |>
  col_vals_equal(columns = vars(n_points), 
                 value = 250,
                 label = "Expected 250 points per station",
                 actions = action_levels(warn_at = 0.001)) |> 
  interrogate()

# Display QA/QC results
station_qaqc
```

Now, lets visualize the distribution of our sampling effort and summarize it by region and subregion to inspect any potential outliers.

```{r}
#| label: fig-map
#| fig-cap: "Interactive map of LPI survey stations"

# Create spatial features
lpi_sites_sf <- uvs_sites |> 
  select(ps_site_id, region, subregion, locality, habitat, exposure, latitude, longitude) |> 
  inner_join(
    lpi_stations |> 
      group_by(ps_site_id) |> 
      summarize(divers = paste(unique(divers), collapse = "/"),
                strata = paste(unique(paste(depth_strata, " (", depth_m, "m)", sep = "")), 
                               collapse = "\n"),
                survey_dist = sum(survey_dist_m),
                n_stations = n_distinct(ps_station_id),
                .groups = "drop"),
    by = "ps_site_id") |> 
  sf::st_as_sf(coords = c("longitude", "latitude"), crs = 4326) 

# Create interactive map
mapview::mapview(lpi_sites_sf,
                 zcol = "exposure",
                 legend = TRUE,
                 map.types = "Esri.WorldImagery",
                 layer.name = "Exposure",
                 popup = leafpop::popupTable(lpi_sites_sf, 
                                             zcol = c("ps_site_id", "strata", "divers", "survey_dist", "habitat", "exposure"))) |> 
  leafem::addMouseCoordinates() |> 
  addFullscreenControl()
```

```{r eval = T, include = T}
#| label: tbl-lpi-stations
#| tbl-cap: "Number of LPI survey stations by depth strata"

lpi_stations |> 
  group_by(region, subregion, depth_strata) |>
  summarise(n = n_distinct(ps_station_id), .groups = "drop") |> 
  pivot_wider(names_from = depth_strata, values_from = n, values_fill = 0) |> 
  mutate(Total = rowSums(across(where(is.numeric)), na.rm = TRUE)) |>
  gt(groupname_col = "region") |> 
  tab_options(table.font.size = 12,
              data_row.padding = px(5),
              table.width = pct(90),
              row_group.as_column = TRUE) |> 
  tab_source_note(source_note = "Depth strata: supershallow (< 6 m), shallow (7-14 m), deep (15-30 m), superdeep: >30m") |> 
  tab_spanner(label = "Depth Strata", 
              columns = c("deep", "shallow", "supershallow")) |> 
  cols_label(subregion = "Subregion") |>
  fmt_number(columns = where(is.numeric), decimals = 0)
```

**Summary:** We conducted bethos LPI surveys at **`r n_distinct(lpi_stations$ps_site_id)`** sites and **`r n_distinct(lpi_stations$ps_station_id)`** stations during the `r exp_id` expedition. Across **`r n_distinct(lpi_stations$region)`** regions, we surveyed a total area of **`r sum(lpi_stations$survey_dist_m)`** m of reef habitats.

### Observations

### Taxa

```{r}
corrections <- c(# Genus 
                 "Lobophyton"           = "Lobophytum",
                 "Lendenfeldeldia"      = "Lendenfeldia",
                 "Lynbya"               = "Lyngbya",
                 "Dendronephyta"        = "Dendronephthya",
                 "Scleronephyta"        = "Scleronephthya",
                 "Cymbastella"          = "Cymbastela",
                 "Halyclonia"           = "Haliclona",
                 "Asteriospicularia"    = "Asterospicularia",
                 "Coalocarteria"        = "Coelocarteria",
                 "Anthipathes"          = "Antipathes",
                 "Elisella"             = "Ellisella",
                 "Microcinidae"         = "Microcionidae",
                 "Darwillenidae"        = "Darwinellidae",
                 "Gibbsmithia"          = "Gibsmithia",
                 "Sandolitha"           = "Sandalolitha",
                 "Phylangia"            = "Phyllangia",
                 "Milipora"             = "Millepora",
                 "Euphillia"            = "Euphyllia",
                 "Psedudodiplora"       = "Pseudodiploria",
                 "Echinophyliia"        = "Echinophyllia",
                 "Pseudoterogorgia"     = "Pseudopterogorgia",
                 "Briaureum"            = "Briareum",
                 "Montrastrea"          = "Montastrea",
                 "Xetospongia"          = "Xestospongia",
                 "Ectyospongia"         = "Ectyoplasia",
                 "Cinachrya"            = "Cinachyra",
                 "Ircina"               = "Ircinia",
                 # Species
                 "brotulata"            = "birotulata",
                 "cribosa"              = "clivosa",
                 "intercepta"           = "intersepta",
                 "hutschyanum"          = "kotschnyanum",
                 "gemmacaea"            = "gemmacea",
                 "acuelata"             = "aculeata",
                 "elephatotus"          = "elephantotus",
                 "chaldicum|chalcidium" = "chalcidicum",   # regex: catch two variants
                 "transvera"            = "transversa",
                 "amata"                = "ammata",
                 "hirsutissma"          = "hirsutissima",
                 "moniasteriata"        = "monasteriata",
                 "nassuta"              = "nasuta",
                 "edyouxi"              = "eydouxi",
                 "hartmanni"            = "hartmani",
                 "phyrgia"              = "phrygia",
                 "urvilliana"           = "urvilleana",
                 "kuekenthallii"        = "kuekenthali",
                 "xamaicaense"          = "xamaycaense",
                 "leutkeni"             = "luetkeni",
                 "corallyticum"         = "coralliphagum")

lpi_observations <- lpi_contacts |>
  mutate(morphotaxon = str_replace_all(morphotaxon, corrections))

lpi_observations$morphotaxon[lpi_observations$morphotaxon == "Gorgonia flabellata"] <- "Gorgonia flabellum"
lpi_observations$morphotaxon[lpi_observations$morphotaxon == "Alosa ruetzeleri"] <- "Ulosa ruetzleri"
lpi_observations$morphotaxon[lpi_observations$morphotaxon == "Halimeda tuna platydisca"] <- "Halimeda tuna"
	
abiotic <- c("Sediment over rock","Sand","Sediment", "Turf", "Barren", "Coral rubble", "Hard coral - dead", "Hard coral - bleached", "EAM - Epilithic Algal Matrix")

lpi_morphotaxa <- lpi_observations |> 
  group_by(morphotaxon) |> 
  summarise(contacts = round(sum(contacts), 2),
            .groups = "drop") |> 
  mutate(pct_contacts = round(100 * contacts / sum(contacts), 2)) |> 
  filter(!morphotaxon %in% abiotic) |> 
  arrange(desc(contacts))

lpi_morphotaxa <- lpi_morphotaxa |> 
  mutate(taxon_clean = morphotaxon |>
           str_remove(regex("\\blike.*", ignore_case = TRUE)) |>          # remove "like..." and everything after
           str_remove(regex("\\bsp(p)?\\.?\\b.*", ignore_case = TRUE)) |> # remove "sp.", "spp.", etc.
           str_remove(regex("\\bcf\\.|aff\\.", ignore_case = TRUE)) |>    # remove "cf.", "aff."
           str_remove_all("[\\?\\(\\)]") |>                               # remove question marks and parens
           str_squish() |> 
           str_to_sentence()) |> 
  mutate(taxon_clean = case_when(str_detect(morphotaxon, "CCA")                         ~ "Corallinales",
                                 morphotaxon == "Dictyota ciliolata (thin)"             ~ "Dictyota ciliolata",
                                 morphotaxon == "Chrysoscystis lewisii"                 ~ "Chrysonephos lewisii",
                                 TRUE ~ taxon_clean)) |> 
  distinct(morphotaxon, taxon_clean, contacts, pct_contacts) |> 
  arrange(desc(pct_contacts))

lpi_morphotaxa |> filter(morphotaxon != taxon_clean)
```

```{r}
# Let's check against our Taxonomic Reference Table

benthos_taxa_lut <- tbl(bq_connection, "taxonomy.benthos") |> 
  filter(!is.na(taxon_name)) |> 
  collect()

# Create name-to-AphiaID mapping

names_to_aphiaID <- benthos_taxa_lut |> 
  select(accepted_aphia_id, taxon_name, accepted_name) |>
  pivot_longer(cols = c("taxon_name", "accepted_name"), names_to = "orig_col", values_to = "lookup_name") |>
  filter(!is.na(lookup_name)) |>
  distinct(accepted_aphia_id, lookup_name) 

lpi_morphotaxa <- lpi_morphotaxa |> 
  left_join(names_to_aphiaID, 
            by = c("taxon_clean" = "lookup_name")) 

lpi_morphotaxa |> 
  filter(is.na(accepted_aphia_id))
```

```{r eval = F}
new_taxa <- lpi_morphotaxa |> 
  filter(is.na(accepted_aphia_id)) |> 
  select(morphotaxon, taxon_clean, pct_contacts)

new_worms_records <- purrr::map_dfr(unique(new_taxa$taxon_clean),
                            ~worrms::wm_records_names(.x)) |> 
  select(taxon_clean = scientificname, aphia_id = AphiaID, rank, 
         name_status = status, accepted_name = valid_name, accepted_aphia_id = valid_AphiaID) |> 
  mutate(rank = str_to_lower(rank))

# Deduplicate 

dupes <- new_worms_records |> 
  get_dupes(taxon_clean)

deduped <- dupes |> 
  filter(name_status == "accepted") |> 
  select(-dupe_count) |> 
  distinct()

new_worms_records <- new_worms_records |> 
  anti_join(dupes) |> 
  bind_rows(deduped) |> 
  select(taxon_clean, aphia_id, rank, name_status, accepted_name, accepted_aphia_id) |> 
  distinct()

get_taxonomic_ranks <- function(id) {
  tryCatch(
    {worrms::wm_classification(id) |>
        select(rank, scientificname) |>
        pivot_wider(names_from = rank, values_from = scientificname) |>
        mutate(accepted_aphia_id = id)},
    error = function(e) {
      tibble(accepted_aphia_id = id)
    })
  }

library(furrr)

new_taxonomy_ranks <- furrr::future_map_dfr(new_worms_records$accepted_aphia_id,
                                            get_taxonomic_ranks,
                                            .options = furrr_options(seed = TRUE)) |>
  clean_names() |>
  select(accepted_aphia_id, kingdom, phylum, class, order, family, genus)

new_taxa <- new_taxa |> 
  left_join(new_worms_records) |> 
  left_join(new_taxonomy_ranks) |> 
  rename(taxon_name = taxon_clean,
         status = name_status) |> 
  select(-morphotaxon, -pct_contacts) 

new_taxa$phylum[new_taxa$class == "Florideophyceae" & is.na(new_taxa$phylum)] <- "Rhodophyta"
new_taxa$phylum[new_taxa$class == "Ulvophyceae" & is.na(new_taxa$phylum)] <- "Chlorophyta"
new_taxa$phylum[new_taxa$class == "Magnoliopsida" & is.na(new_taxa$phylum)] <- "Tracheophyta"

# Assign functional group

turf_genera       <- c("Cladophoropsis", "Cladophora", "Dictyosphaeria", "Chlorodesmis", "Ceratodictyon", "Gelidium", "Millerella", "Anadyomene", "Asparagopsis", "Chrysonephos", "Rhodymenia",
                       "Wrangelia")

cca_genera        <- c("Pneophyllum", "Hydrolithon", "Porolithon", "Neogoniolithon", "Lithophyllum", "Sporolithon", "Lithothamnion", "Harveylithon", "Jania", "Mastophora")

cyano_genera      <- c("Lyngbya", "Symploca", "Symplocastrum", "Phormidium", "Schizothrix", "Caldora")

other_order       <- c("Zoantharia","Actiniaria","Antipatharia","Corallimorpharia")

encrusting_genera <- c("Lobophora", "Haematocelis", "Peyssonnelia", "Ralfsia")

erect_genera      <- c("Caulerpa", "Halimeda", "Galaxaura", "Avrainvillea", "Valonia", "Udotea", "Rhipilia", "Microdictyon", "Tricleocarpa", "Halymenia", "Gibsmithia", "Tydemania",
                       "Cheilosporum", "Portieria", "Callophycus", "Kraftalia", "Rhipidosiphon", "Actinotrichia", "Dichotomaria", "Schizymenia", "Titanophora", "Predaea", "Padina",
                       "Amphiroa", "Neomeris", "Codium", "Bornetella", "Hypnea", "Dasya", "Bryopsis", "Dictyota", "Dictyopteris", "Laurencia", "Acanthophora", "Stypopodium",
                       "Penicillus", "Canistrocarpus", "Rhipocephalus", "Haloplegma", "Yuzurua", "Sargassum")

new_taxa <- new_taxa %>%
  mutate(functional_group = case_when(accepted_name == "Turbinaria turbinata"              ~ "algae_erect",
                                      accepted_name == "Martensia pavonia"                 ~ "turf",
                                      genus == "Halophila" |
                                        accepted_name == "Syringodium filiforme"           ~ "seagrass",
                                      #Erect algae 
                                      genus %in% erect_genera                              ~ "algae_erect",
                                      #Encrusting algae 
                                      genus %in% encrusting_genera                         ~ "algae_encrusting",
                                      # CCA
                                      genus %in% cca_genera                                ~ "cca",
                                      # TURF
                                      genus %in% turf_genera                               ~ "turf",
                                      # Cyanobacteria
                                      class  == "Cyanophyceae"                             ~ "cyanobacteria",
                                      # Corals
                                      order  == "Scleractinia"                             ~ "hard_coral",
                                      class  == "Octocorallia"                             ~ "soft_coral",
                                      # Inverts 
                                      phylum == "Porifera"                                 ~ "sponges",
                                      phylum == "Bryozoa"                                  ~ "bryozoans",
                                      phylum == "Echinodermata"                            ~ "echinoderms",
                                      phylum == "Mollusca"                                 ~ "molluscs",
                                      phylum == "Annelida"                                 ~ "worms",
                                      phylum == "Foraminifera"                             ~ "forams",
                                      class  == "Hydrozoa"                                 ~ "hydrozoans",
                                      class  == "Ascidiacea" | accepted_name == "Tunicata" ~ "ascidians",
                                      order  %in% other_order                              ~ "other_cnidarians",
                                      # Fillers
                                      order  == "Corallinales"                             ~ "cca"
                                      )) 

# IUCN status

iucn_db <- read_csv(file.path(ps_paths$datasets, 
                              "iucn-redlist-marine-species",  
                              "joined_and_resolved_taxa.csv"))

iucn_priority <- c("CR", "EN", "VU", "NT", "LC", "DD", "NE")

iucn_clean <- iucn_db |> 
  rename(accepted_name = taxon_valid_name) |> 
  filter(accepted_name %in% new_taxa$accepted_name) |> 
  distinct(accepted_name, iucn_redlist_cat, iucn_taxon_id) |> 
  mutate(iucn_redlist_cat = case_when(str_detect(iucn_redlist_cat, "Critically Endangered") ~ "CR",
                                      str_detect(iucn_redlist_cat, "Endangered") ~ "EN",
                                      str_detect(iucn_redlist_cat, "Vulnerable") ~ "VU",
                                      str_detect(iucn_redlist_cat, "Near Threatened") ~ "NT",
                                      str_detect(iucn_redlist_cat, "Least Concern") ~ "LC",
                                      str_detect(iucn_redlist_cat, "Data Deficient") ~ "DD",
                                      str_detect(iucn_redlist_cat, "Extinct") ~ "EX",
                                      str_detect(iucn_redlist_cat, "Lower Risk/least concern") ~ "LC",
                                      str_detect(iucn_redlist_cat, "Lower Risk/near threatened") ~ "NT",
                                      TRUE ~ NA_character_)) |> 
  mutate(iucn_rank = match(iucn_redlist_cat, c("EX", iucn_priority))) |> 
  group_by(accepted_name) |> 
  arrange(iucn_rank) |> 
  slice(1) |> 
  ungroup() |> 
  select(-iucn_rank) |> 
  rename(iucn_cat = iucn_redlist_cat,
         iucn_sis_id = iucn_taxon_id)

new_taxa <- new_taxa |> 
  left_join(iucn_clean)

# upload to BQ

bq_table_upload(bq_table("pristine-seas", "taxonomy", "benthos"),
                values = new_taxa,
                create_disposition = "CREATE_NEVER",
                write_disposition = "WRITE_APPEND")
```

```{r}
lpi_morphotaxa <- lpi_morphotaxa |> 
  left_join(benthos_taxa_lut |> 
              filter(!aphia_id %in% c(224174, 1341, 224179), !is.na(accepted_aphia_id)) |> 
              distinct(accepted_aphia_id, accepted_name, rank, functional_group, family)) 
```

```{r}
lpi_morphotaxa |> 
  mutate(rank = coalesce(rank, morphotaxon)) |> 
  group_by(rank) |> 
  summarize(n_morphotaxa = n_distinct(morphotaxon),
            n_aphia_id = n_distinct(accepted_aphia_id),
            contacts = sum(contacts),
            .groups = "drop") |> 
  arrange(desc(contacts)) |> 
  mutate(pct_contacts = round(100*contacts/sum(contacts), 2))

lpi_morphotaxa |> 
  filter(!is.na(family)) |> 
  group_by(family) |> 
  summarize(n_morphotaxa = n_distinct(morphotaxon),
            n_aphia_id = n_distinct(accepted_aphia_id),
            contacts = sum(contacts),
            .groups = "drop") |> 
  arrange(desc(contacts)) |> 
    mutate(pct_contacts = round(100*contacts/sum(contacts), 2))

lpi_morphotaxa |> 
  group_by(functional_group) |> 
  summarize(n_morphotaxq = n_distinct(morphotaxon),
            n_aphia_id = n_distinct(accepted_aphia_id),
            contacts = sum(contacts),
            .groups = "drop") |> 
  arrange(desc(contacts)) |> 
  mutate(pct_contacts = round(100*contacts/sum(contacts), 2)) # Excluding the non taxa groups e.g., barren

lpi_morphotaxa |> filter(is.na(functional_group))
```

```{r}
# Combine with contacts data

clean_lpi <- lpi_observations |> 
  left_join(lpi_morphotaxa |> 
              distinct(morphotaxon, accepted_name, accepted_aphia_id, rank, functional_group, family), 
            by = "morphotaxon") |> 
  mutate(functional_group = case_when(morphotaxon %in% c("Barren", "Sediment", "Rubble/barren", "Sand", "Sediment over rock") ~ "sediment|rubble|barren", 
                                      morphotaxon == "Turf" ~ "turf",
                                      TRUE ~ functional_group)) |> 
  select(ps_station_id, exp_id, diver, depth_m, transect_label, transect_section, 
         morphotaxon, accepted_name, accepted_aphia_id, rank, family, functional_group, contacts)
```

```{r}
clean_lpi |> 
  group_by(functional_group) |> 
  summarize(n_morphotaxa = n_distinct(morphotaxon),
            n_AphiaIDs   = n_distinct(accepted_aphia_id),
            contacts     = sum(contacts),
            .groups = "drop") |> 
  mutate(pct_contacts = round(100*contacts/sum(contacts), 2)) |> 
  arrange(desc(pct_contacts)) 
```

```{r}
clean_lpi |> 
  group_by(ps_station_id) |> 
  summarize(pct_coral = round(100*sum(contacts[functional_group == "hard_coral"], na.rm = T)/sum(contacts), 1)) |> 
  ungroup() |> 
  left_join(lpi_stations |> select(ps_station_id, ps_site_id, region)) |> 
  group_by(region, ps_site_id) |> 
  summarize(mean(pct_coral)) |> 
  arrange(ps_site_id)
```

## Calculate: % Cover by taxa and station

```{r}
cover_by_station_and_taxa <- clean_lpi |>
  filter(transect_section != "Off") |>

  # 1. Section-level % cover (for SD)
  group_by(ps_station_id, transect_label, transect_section) |>
  mutate(pct_cover_section = 100 * contacts / sum(contacts)) |>
  ungroup() |>

  # 2. Fill missing taxa Ã— section combos
  group_by(diver, ps_station_id, transect_label) |>
  complete(
    nesting(transect_section),
    nesting(functional_group, morphotaxon, accepted_name, accepted_aphia_id, rank, family),
    fill = list(contacts = 0, pct_cover_section = 0)
  ) |>
  ungroup() |>

  # 3. Compute total contacts and SD across sections
  group_by(diver, ps_station_id, morphotaxon, accepted_name, accepted_aphia_id, functional_group, rank, family) |>
  summarize(
    total_contacts = sum(contacts),
    pct_cover_sd = sd(pct_cover_section),
    .groups = "drop"
  ) |>

  # 4. Compute compositional % cover
  group_by(ps_station_id) |>
  mutate(pct_cover = 100 * total_contacts / sum(total_contacts)) |>
  ungroup() |> 
  filter(total_contacts > 0)
```

```{r}
cover_by_station_and_taxa <- cover_by_station_and_taxa |> 
  left_join(lpi_stations |> 
              select(exp_id, ps_station_id, ps_site_id, region, subregion, habitat, exposure, depth_strata, depth_m),
            by = "ps_station_id") |> 
  select(ps_station_id, ps_site_id, exp_id, region, subregion, habitat, exposure, depth_strata, depth_m, 
         diver, morphotaxon, accepted_name,  accepted_aphia_id, rank, family, functional_group, everything())

grps_order <- c("cyanobacteria", "eam","sediment|rubble|barren", "other", "turf", "algae_encrusting",
                "algae_erect","sponges", "soft_coral","cca", "hard_coral")

cover_by_station_and_group <- cover_by_station_and_taxa |> 
  mutate(functional_group = case_when(functional_group %in% c("bryozoans","worms","echinoderms", "molluscs", "hydrozoans", "ascidians", "other_cnidarians", "seagrass") ~ "other",
                                      functional_group %in% c("hard_coral_dead") ~ "sediment|rubble|barren",
                                      TRUE ~ functional_group)) |> 
  group_by(region, subregion, ps_site_id, ps_station_id, depth_strata, functional_group) |> 
  summarize(pct_cover = round(sum(pct_cover),2),
            .groups = "drop") |> 
  pivot_wider(names_from = functional_group, values_from = pct_cover, values_fill = 0) |> 
  pivot_longer(cols = -c(ps_station_id, region, subregion, depth_strata, ps_site_id), names_to = "functional_group", values_to = "pct_cover") |>  
  mutate(functional_group = fct_relevel(functional_group, grps_order))
```

## Station Summary

Aggregate metrics at the station level for ecological analysis.
  
```{r}
n_morphotaxa <- cover_by_station_and_taxa |> 
  group_by(ps_station_id) |> 
  summarize(n_morphotaxa = n_distinct(morphotaxon),
            .groups = "drop") 

station_summary <- lpi_stations |> 
  left_join(n_morphotaxa) |> 
  left_join(cover_by_station_and_group |>  
              select(-region, -depth_strata, -subregion) |> 
              pivot_wider(names_from = functional_group, 
                          names_prefix = "pct_",
                          values_from = c(pct_cover), 
                          values_fill = 0) |> 
              janitor::clean_names() |> 
              rename(pct_coral = pct_hard_coral,
                     pct_rubble = pct_sediment_rubble_barren,
                     pct_cyano = pct_cyanobacteria,
                     pct_algae_encrust = pct_algae_encrusting))

station_summary |> 
  filter(habitat != "seagrass") |> 
  group_by(region, ps_site_id, habitat) |> 
  summarise(across(contains("pct"), mean), .groups = "drop") |> 
  ungroup() |> 
  group_by(region, habitat) |> 
  summarise(across(contains("pct"), mean), .groups = "drop") |> 
  mutate_if(is.numeric, round, 1) 
```

## Explore 

Aggregate metrics at the station level for ecological analysis.

```{r}
cover_by_station_and_group |> 
  mutate(site = str_extract(ps_site_id, "[^_]+$")) |> 
  filter(depth_strata != "supershallow") |> 
  ggplot()+
  geom_col(aes(site, pct_cover, fill = functional_group))+
  facet_grid(depth_strata~region, scales = "free")+
  scale_fill_manual(values = ps_colors("functional_groups"))+
  ggthemes::theme_fivethirtyeight()+
  labs(x = NULL, y = "Benthic composition (% of station total)",
       fill = "Functional group",
       title = "Benthic cover composition by site, region, and depth")+
  theme(panel.grid.major.x = element_blank(),
        panel.grid.minor = element_blank(),
        strip.text = element_text(face = "bold"),
        legend.position = "bottom",
        legend.key.height = unit(4, "mm"),
        axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```

```{r}
cover_by_station_and_group |> 
  group_by(region, depth_strata, functional_group) |> 
  summarize(pct_cover = mean(pct_cover)) |> 
  ungroup() |> 
  #filter(depth_strata != "supershallow") |> 
  ggplot()+
  geom_col(aes(x = depth_strata, y = pct_cover, fill = functional_group))+
  facet_wrap(~region , scales = "free")+
  scale_fill_manual(values = ps_colors("functional_groups"))+
  ggthemes::theme_fivethirtyeight()+
  labs(x = NULL, y = "Benthic composition (% of station total)",
       fill = "Functional group",
       title = "Benthic cover composition by subregion, and depth")+
  theme(panel.grid.major.x = element_blank(),
        panel.grid.minor = element_blank(),
        strip.text = element_text(face = "bold"),
        legend.position = "bottom",
        legend.key.height = unit(4, "mm"),
        axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```


```{r}
#| label: fig-missingness-stations
#| fig-cap: "Missingness plot for station summary"
#| 
naniar::vis_miss(station_summary)
```

Examine how key ecological metrics vary across depth strata to understand vertical zonation patterns.

```{r}
#| label: fig-transects-summary
#| fig-cap: "Comparison of species richness, total count, density, and biomass across depth strata"

station_summary |> 
  select(ps_station_id, depth_strata, pct_coral, pct_cca, pct_cyano, pct_turf, pct_algae_erect, pct_rubble) |> 
  pivot_longer(cols = -c(ps_station_id, depth_strata),
               names_to = "functional_group",
               values_to = "pct_cover") |> 
  ggplot(aes(x = depth_strata, y = pct_cover, fill = depth_strata)) +
  geom_boxplot(alpha = 0.6, color = "gray40", outlier.shape = NA) +
  geom_jitter(width = 0.2, size = 1, alpha = 0.5, color = "gray30") +
  facet_wrap(~functional_group, scales = "free_y") +
  labs(x = "", 
       y = "",
       title = "**Cover by Depth Strata**",
       subtitle = "Comparison of % cover by main functional groups across depth strata") +
  theme_minimal(base_size = 14) +
  theme(legend.position = "none",
        plot.title = element_markdown(size = 18, face = "bold"),
        plot.subtitle = element_text(size = 12, face = "italic"),
        strip.text = element_text(size = 12, face = "bold"),
        panel.grid.minor = element_blank(),
        panel.grid.major.y = element_line(color = "gray90"),
        panel.grid.major.x = element_blank())+
  scale_fill_manual(values = ps_colors("depth_strata"))
```

Identify and visualize the most cover-dominant species to understand community drivers.

```{r warning = F}
#| label: fig-top-taxa
#| fig-cap: "Biomass distributions for top taxa and depth strata"
#| fig-width: 12
#| fig-height: 8

library(ggplot2)
library(dplyr)
library(ggtext)
library(RColorBrewer)

# Identify major taxa based on average % cover (after filling with zeros)

plot_df <- cover_by_station_and_taxa |> 
  select(ps_station_id, morphotaxon, accepted_name, functional_group, accepted_aphia_id, rank, pct_cover, total_contacts) |> 
  complete(ps_station_id, 
           nesting(morphotaxon, accepted_name, functional_group, accepted_aphia_id, rank),
           fill = list(pct_cover = 0,
                       total_contacts = 0))

taxa_means <- plot_df |> 
  group_by(morphotaxon) |> 
  summarise(mean_cover = mean(pct_cover, na.rm = TRUE),
            median_cover = median(pct_cover, na.rm = TRUE)) |> 
  arrange(desc(median_cover), desc(mean_cover)) 

top_taxa <- taxa_means |> 
  head(12) |> 
  pull(morphotaxon)

# Compute means and medians for each depth stratum
depth_summary <- plot_df |> 
  left_join(lpi_stations, by = "ps_station_id") |> 
  filter(morphotaxon %in% top_taxa) |> 
  group_by(morphotaxon, depth_strata) |> 
  summarise(mean_cover = mean(pct_cover, na.rm = TRUE),
    median_cover = median(pct_cover, na.rm = TRUE),
    .groups = "drop") 

# Plot

plot_df |> 
  left_join(lpi_stations) |> 
  filter(morphotaxon %in% top_taxa) |> 
  ggplot(aes(x = depth_strata, y = pct_cover, fill = morphotaxon)) +
  geom_boxplot(outlier.shape = NA, alpha = 0.5, color = "gray30") +
  geom_jitter(aes(color = morphotaxon), width = 0.2, size = 1.2, alpha = 0.6)+
  geom_text(data = depth_summary, 
            aes(label = paste0("Med: ", round(median_cover, 2)), 
                y = median_cover), 
            vjust = -0.5, size = 3, color = "black") +
  geom_text(data = depth_summary, 
            aes(label = paste0("Mean: ", round(mean_cover, 2)), 
                y = mean_cover), 
            vjust = 1.5, size = 3, color = "red")+
  facet_wrap(~ morphotaxon, scales = "free_y") +
  scale_y_continuous(trans = "log10",
                     breaks = c(0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000),
                     labels = c("0", "0.001", "0.01", "0.1", "1", "10", "100", "1000"))+
  labs(x = "", 
       y = "% cover", 
       title = "**% Cover by Major Taxa**",
       subtitle = "Depth-stratified boxplots with jittered observations, mean (red) and median (black) labels") +
  theme_minimal(base_size = 14) +
  theme(legend.position = "none",
    plot.title = element_markdown(size = 18, face = "bold"),
    plot.subtitle = element_text(size = 12, face = "italic"),
    strip.text = element_text(size = 12, face = "bold"),
    panel.grid.minor = element_blank(),
    panel.grid.major.y = element_line(color = "gray90"),
    panel.grid.major.x = element_blank())+
  paletteer::scale_fill_paletteer_d("ggsci::default_igv") +
  paletteer::scale_color_paletteer_d("ggsci::default_igv")
```

## Database integration

### Pre-upload Validation

Final validation checks before uploading to the Pristine Seas Science Database.

```{r}
# Validate data completeness
validation_summary <- list(
  stations = list(
    total_records = nrow(station_summary),
    complete_records = sum(complete.cases(station_summary |> select(-locality))),
    missing_critical = sum(is.na(station_summary$ps_station_id) | 
                          is.na(station_summary$exp_id) | 
                          is.na(station_summary$region))
  ),
  contacts = list(
    total_points = sum(clean_lpi$contacts),
    total_records = nrow(clean_lpi),
    complete_records = sum(complete.cases(clean_lpi)),
    species_count = n_distinct(clean_lpi$accepted_name),
    morphotaxon_count = n_distinct(clean_lpi$morphotaxon)
  )
)

# Display validation summary
cat("ðŸ“Š Data Validation Summary\n")
cat("========================\n\n")

cat("Station Summary:\n")
cat("  - Total records:", validation_summary$stations$total_records, "\n")
cat("  - Complete records:", validation_summary$stations$complete_records, "\n")
cat("  - Missing critical fields:", validation_summary$stations$missing_critical, "\n\n")

cat("Points:\n")
cat("  - Total points:", validation_summary$contacts$total_points, "\n")
cat("  - Total records:", validation_summary$contacts$total_records, "\n")
cat("  - Complete records:", validation_summary$contacts$total_records, "\n")
cat("  - Morphotaxa:", validation_summary$contacts$morphotaxon_count, "\n")
cat("  - Unique species:", validation_summary$contacts$species_count, "\n\n")
```

```{r}
cover_by_station_and_taxa <- cover_by_station_and_taxa |> 
  rename(contacts = total_contacts)

station_summary <- station_summary |> 
  select(ps_station_id, ps_site_id, exp_id, region, subregion, locality, 
         habitat, exposure, divers, depth_m, depth_strata,
         n_transects, survey_dist_m, n_points, total_morphotaxa = n_morphotaxa, pct_coral, pct_cca, pct_cyano, everything()) 

clean_lpi <- clean_lpi |> 
  select(ps_station_id, exp_id, diver, depth_m, transect_label, transect_section, morphotaxon, accepted_name, accepted_aphia_id, rank, family, functional_group, contacts, everything())

write_csv(cover_by_station_and_taxa, file.path(exp_path, "data/primary/output/benthos/lpi_cover_by_station_and_taxa.csv"))
write_csv(station_summary, file.path(exp_path, "data/primary/output/benthos/lpi_station_summary.csv"))
write_csv(clean_lpi, file.path(exp_path, "data/primary/output/benthos/lpi_contacts.csv"))
```

```{r}
station_summary |> 
  filter(habitat != "seagrass") |> 
  group_by(region, ps_site_id) |> 
  summarise(across(contains("pct"), mean), .groups = "drop") |> 
  ungroup() |> 
  group_by(region) |> 
  summarise(across(contains("pct"), mean), .groups = "drop") |> 
  mutate_if(is.numeric, round, 1) 
```

### Upload to BigQuery

Finally, Upload the validated and processed data to BigQuery, maintaining data integrity and traceability.

```{r}
bq_table_upload(bq_table("pristine-seas", "uvs", "lpi_stations"),
                values = station_summary,
                create_disposition = "CREATE_NEVER",
                write_disposition = "WRITE_APPEND")

bq_table_upload(bq_table("pristine-seas", "uvs", "lpi_contacts"),
                values = clean_lpi,
                create_disposition = "CREATE_NEVER",
                write_disposition = "WRITE_APPEND")

bq_table_upload(bq_table("pristine-seas", "uvs", "lpi_cover_by_taxa"),
                values = cover_by_station_and_taxa,
                create_disposition = "CREATE_NEVER",
                write_disposition = "WRITE_APPEND")
```
